{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "extreme-psychology",
   "metadata": {
    "id": "extreme-psychology"
   },
   "outputs": [],
   "source": [
    "import pytraj as pt\n",
    "import parmed as pmd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import networkx as nx\n",
    "import scipy\n",
    "import pickle as pkl\n",
    "from tqdm.notebook import tqdm\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from scipy import exp\n",
    "from kneed import KneeLocator as KneedLoc\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da2cb34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = 'Helvetica'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-incentive",
   "metadata": {
    "id": "featured-incentive"
   },
   "source": [
    "<h1> Graph Normalization and Thresholding </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "foreign-singles",
   "metadata": {
    "id": "foreign-singles"
   },
   "outputs": [],
   "source": [
    "def compute_normalized_graph(matrix):\n",
    "    row_sums = matrix.sum(axis=1)\n",
    "    size = matrix.shape[0]\n",
    "    new_matrix = np.zeros((size,size))\n",
    "    for x,row in enumerate(matrix):\n",
    "        #for every column's row\n",
    "        for y, val in enumerate(row):\n",
    "            #for every value in row\n",
    "            current = val / row_sums[x] if row_sums[x] != 0 else 0\n",
    "            new_matrix[x,y] = max([current,new_matrix[y,x]])\n",
    "            new_matrix[y,x] = max([current,new_matrix[x,y]])\n",
    "\n",
    "    return new_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "frank-cornwall",
   "metadata": {
    "id": "frank-cornwall"
   },
   "outputs": [],
   "source": [
    "def threshold_normalized_graph(matrix, cutoff):\n",
    "    size = matrix.shape[0]\n",
    "    new_matrix = np.zeros((size,size))\n",
    "    for x,row in enumerate(matrix):\n",
    "        for y, val in enumerate(row):\n",
    "            new_matrix[x,y] = 1 if matrix[x,y] > cutoff else 0\n",
    "\n",
    "    return new_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-might",
   "metadata": {
    "id": "empty-might"
   },
   "source": [
    "<h1> Pairwise Energy Tensor Analysis </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "vital-heater",
   "metadata": {
    "id": "vital-heater"
   },
   "outputs": [],
   "source": [
    "def thresh_and_norm_matrix(tensor,channel,threshold):\n",
    "    #same function as above, just quicker to access here outside of the tensor class\n",
    "    '''\n",
    "    channel (int): the energy channel to compute for\n",
    "    threshold (float): the cutoff value\n",
    "\n",
    "    returns : (numpy.ndarray) matrix of matrices summed over common edges, normalized,\n",
    "    and thresholded\n",
    "    '''\n",
    "    energy_tensor = torch.Tensor(tensor[:,channel])\n",
    "    sum_matrix = torch.sum(energy_tensor, dim=0).numpy()\n",
    "    normalized = compute_normalized_graph(sum_matrix)\n",
    "    #thresholded is binary\n",
    "    thresholded = threshold_normalized_graph(normalized,threshold)\n",
    "    weighted_threshold = thresholded * normalized\n",
    "    return (thresholded,weighted_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-surveillance",
   "metadata": {
    "id": "overhead-surveillance"
   },
   "source": [
    "<h1> Heat Kernel Analysis:</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-snake",
   "metadata": {
    "id": "later-snake"
   },
   "source": [
    "### Heat Kernel PCA (See: https://link.springer.com/chapter/10.1007/11815921_18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sustained-devon",
   "metadata": {
    "id": "sustained-devon"
   },
   "outputs": [],
   "source": [
    "def matrix_exponentiation(eigenvectors,eigenvalues,t):\n",
    "    '''\n",
    "    Raise e^matrix where matrix is a square\n",
    "    '''\n",
    "    shape = eigenvectors.shape[0]\n",
    "    processed_eigenvalues = np.exp(-t*eigenvalues)\n",
    "    e_diagonal = np.diag(processed_eigenvalues)\n",
    "    return eigenvectors.dot(e_diagonal).dot(eigenvectors.transpose())\n",
    "\n",
    "def get_heat_kernel(matrix,t):\n",
    "    laplacian = scipy.sparse.csgraph.laplacian(matrix,normed=True)\n",
    "    (eigenvalues,eigenvectors) = np.linalg.eigh(laplacian)\n",
    "    x = matrix_exponentiation(eigenvectors,eigenvalues,t)\n",
    "    x = np.round(x, decimals = 6)\n",
    "    return x\n",
    "\n",
    "def kernel_from_energy_tensor_thresh(tensor,threshold,time):\n",
    "    kernels = np.zeros((tensor.shape[0], tensor.shape[2], tensor.shape[2]))\n",
    "    for i, matrix in enumerate(tensor):\n",
    "        normalized = compute_normalized_graph(matrix)\n",
    "        thresholded = threshold_normalized_graph(normalized,threshold)\n",
    "        final_mat = thresholded * normalized\n",
    "        kernel = get_heat_kernel(final_mat, time)\n",
    "        kernels[i] = kernel\n",
    "\n",
    "    return kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "organized-hurricane",
   "metadata": {
    "id": "organized-hurricane"
   },
   "outputs": [],
   "source": [
    "def get_pca(kernel,dim):\n",
    "    pca = PCA(n_components=dim)\n",
    "    pca.fit(kernel)\n",
    "    transformed = pca.transform(kernel)\n",
    "    return (transformed, pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "future-pledge",
   "metadata": {
    "id": "future-pledge"
   },
   "outputs": [],
   "source": [
    "def make_shared_pca_df(kernels, num_components, show_var=False):\n",
    "    dfs = []\n",
    "    eigens=[]\n",
    "    for kernel in kernels:\n",
    "        (pcs, var) = get_pca(kernel, num_components)\n",
    "        df = pd.DataFrame(pcs)\n",
    "        dfs.append(df)\n",
    "        if show_var:\n",
    "            eigens+=[var]\n",
    "\n",
    "    return (eigens, pd.concat(dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "binary-wisconsin",
   "metadata": {
    "id": "binary-wisconsin"
   },
   "outputs": [],
   "source": [
    "#assigns res number to each pcs embedding\n",
    "def embedded_res_assign(frame_tot,res_tot,df):\n",
    "    lst=np.zeros(frame_tot*res_tot)\n",
    "    n=res_tot\n",
    "    res_idx=[]\n",
    "    i=1\n",
    "    res=1\n",
    "    while i<=len(lst):\n",
    "        if res>res_tot:\n",
    "            res=1\n",
    "            res_idx.append(res)\n",
    "        else:\n",
    "            res_idx.append(res)\n",
    "        res+=1\n",
    "        i+=1\n",
    "    df['res'] =res_idx\n",
    "    return df\n",
    "\n",
    "def embedded_frame_assign(frame_tot,res_tot,df):\n",
    "    lst=np.zeros(frame_tot*res_tot)\n",
    "    n=res_tot\n",
    "    frame_idx=[]\n",
    "    i=1\n",
    "    frame=0\n",
    "    while i<=len(lst):\n",
    "        if (i)%n==0:\n",
    "            frame_idx.append(frame)\n",
    "            frame+=1\n",
    "        else:\n",
    "            frame_idx.append(frame)\n",
    "        i+=1\n",
    "    df['frame'] =frame_idx\n",
    "    return df\n",
    "\n",
    "\n",
    "def heat_map(kernel,pcs):\n",
    "    diag_els=[]\n",
    "    for matrix in kernel[:]:\n",
    "        diag_element=np.diag(matrix)\n",
    "        diag_els+=[diag_element]\n",
    "    diag_flat=np.concatenate(diag_els)\n",
    "    #set the column called 'heat' to the flattened diagonal matrix consisting of the diagonal elements of the kernel\n",
    "    pcs['heat'] =diag_flat\n",
    "    return pcs\n",
    "\n",
    "#range_color1=[0.0112,0.0134]\n",
    "range_color1=[]\n",
    "xrng=[-0.013, 0.024]\n",
    "yrng=[-0.013, 0.015]\n",
    "def heat_map_plot(kernel,pcs,pc_b,title_name):\n",
    "    heat_pcs=heat_map(kernel,pcs)\n",
    "    heat_pcs_res0=embedded_res_assign(100,199,heat_pcs)\n",
    "    heat_pcs_res=embedded_frame_assign(100,199,heat_pcs)\n",
    "    fig=px.scatter(heat_pcs_res, x= 0, y= pc_b, color=\"heat\",range_color=range_color1,hover_data=[\"heat\",\"res\",\"frame\"], labels={ \"0\": \"PC1\",\"2\": \"PC3\"},title=title_name)\n",
    "    fig.update_layout(title_x=0.5)\n",
    "    fig.update_layout(title_yanchor=\"top\")\n",
    "    fig.update_traces(marker=dict(size=10))\n",
    "    fig.update_xaxes(range=xrng)\n",
    "    fig.update_yaxes(range=yrng)\n",
    "    fig.update_layout(font=dict(\n",
    "        family=\"Arial\",\n",
    "        size=16))\n",
    "    fig.show()\n",
    "\n",
    "def three_dim_heat_map_plot(kernel,pcs):\n",
    "    heat_pcs=heat_map(kernel,pcs)\n",
    "    heat_pcs_res0=embedded_res_assign(100,199,heat_pcs)\n",
    "    heat_pcs_res=embedded_frame_assign(100,199,heat_pcs)\n",
    "    fig=px.scatter_3d(pcs, x=0, y=1, z=2,color=\"heat\",hover_data=[\"heat\",\"res\",\"frame\"])\n",
    "    fig.update_traces(marker_size = 3)\n",
    "    fig.show()\n",
    "\n",
    "def heat_map_plot_resid(kernel,pcs,pc_b):\n",
    "    heat_pcs=heat_map(kernel,pcs)\n",
    "    heat_pcs_res=embedded_res_assign(100,199,heat_pcs)\n",
    "    fig=px.scatter(heat_pcs_res, x= 0, y= pc_b, color=\"res\",color_continuous_scale=px.colors.sequential.Turbo)\n",
    "    fig.update_traces(marker=dict(size=10))\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "def heat_res_frame_map(kernel,pcs,num_frame,num_res):\n",
    "    heat_pcs=heat_map(kernel,pcs)\n",
    "    heat_pcs_res=embedded_res_assign(num_frame,num_res,heat_pcs)\n",
    "    heat_pcs_res_frame=embedded_frame_assign(num_frame,num_res,heat_pcs)\n",
    "    return heat_pcs_res_frame\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "violent-tutorial",
   "metadata": {
    "id": "violent-tutorial"
   },
   "source": [
    "# Energy Tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1944c677",
   "metadata": {
    "id": "1944c677"
   },
   "outputs": [],
   "source": [
    "#etensor indexing: frame, row, column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77c4e74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadData(file):\n",
    "    toReturn = []\n",
    "    with np.load(file) as data:\n",
    "        lst = data.files\n",
    "        for item in lst:\n",
    "            toReturn.append(data[item])\n",
    "    if len(toReturn) > 1: raise ValueError(f\"file has length {len(toReturn)}\")\n",
    "    return toReturn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "polar-words",
   "metadata": {
    "id": "polar-words"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.01198364, 0.0108311 , ..., 0.0023943 ,\n",
       "         0.00161442, 0.00263934],\n",
       "        [0.01198364, 0.        , 0.01362826, ..., 0.00242732,\n",
       "         0.00233814, 0.00275619],\n",
       "        [0.0108311 , 0.01362826, 0.        , ..., 0.00242732,\n",
       "         0.00228289, 0.00276868],\n",
       "        ...,\n",
       "        [0.0023943 , 0.00242732, 0.00242732, ..., 0.        ,\n",
       "         0.01589954, 0.01289568],\n",
       "        [0.00161442, 0.00233814, 0.00228289, ..., 0.01589954,\n",
       "         0.        , 0.02085607],\n",
       "        [0.00263934, 0.00275619, 0.00276868, ..., 0.01289568,\n",
       "         0.02085607, 0.        ]],\n",
       "\n",
       "       [[0.        , 0.01234517, 0.01060522, ..., 0.00241113,\n",
       "         0.0016312 , 0.00267983],\n",
       "        [0.01234517, 0.        , 0.0139776 , ..., 0.0024264 ,\n",
       "         0.00236173, 0.00277494],\n",
       "        [0.01060522, 0.0139776 , 0.        , ..., 0.00245866,\n",
       "         0.00233626, 0.0028311 ],\n",
       "        ...,\n",
       "        [0.00241113, 0.0024264 , 0.00245866, ..., 0.        ,\n",
       "         0.0163963 , 0.01374556],\n",
       "        [0.0016312 , 0.00236173, 0.00233626, ..., 0.0163963 ,\n",
       "         0.        , 0.02120978],\n",
       "        [0.00267983, 0.00277494, 0.0028311 , ..., 0.01374556,\n",
       "         0.02120978, 0.        ]],\n",
       "\n",
       "       [[0.        , 0.0125668 , 0.01090305, ..., 0.00235531,\n",
       "         0.00157956, 0.00256016],\n",
       "        [0.0125668 , 0.        , 0.01381163, ..., 0.00242926,\n",
       "         0.00232668, 0.00271129],\n",
       "        [0.01090305, 0.01381163, 0.        , ..., 0.002416  ,\n",
       "         0.00229323, 0.00270868],\n",
       "        ...,\n",
       "        [0.00235531, 0.00242926, 0.002416  , ..., 0.        ,\n",
       "         0.01628424, 0.01279544],\n",
       "        [0.00157956, 0.00232668, 0.00229323, ..., 0.01628424,\n",
       "         0.        , 0.01992553],\n",
       "        [0.00256016, 0.00271129, 0.00270868, ..., 0.01279544,\n",
       "         0.01992553, 0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.        , 0.01484925, 0.01036178, ..., 0.00219504,\n",
       "         0.00149378, 0.00254964],\n",
       "        [0.01484925, 0.        , 0.01289645, ..., 0.00223949,\n",
       "         0.00181786, 0.00264102],\n",
       "        [0.01036178, 0.01289645, 0.        , ..., 0.00239633,\n",
       "         0.00179857, 0.00280778],\n",
       "        ...,\n",
       "        [0.00219504, 0.00223949, 0.00239633, ..., 0.        ,\n",
       "         0.01151143, 0.01471139],\n",
       "        [0.00149378, 0.00181786, 0.00179857, ..., 0.01151143,\n",
       "         0.        , 0.01905458],\n",
       "        [0.00254964, 0.00264102, 0.00280778, ..., 0.01471139,\n",
       "         0.01905458, 0.        ]],\n",
       "\n",
       "       [[0.        , 0.01416489, 0.0112768 , ..., 0.00217362,\n",
       "         0.00144139, 0.0025025 ],\n",
       "        [0.01416489, 0.        , 0.01423934, ..., 0.00224506,\n",
       "         0.00187336, 0.00262834],\n",
       "        [0.0112768 , 0.01423934, 0.        , ..., 0.00234451,\n",
       "         0.00188705, 0.00271677],\n",
       "        ...,\n",
       "        [0.00217362, 0.00224506, 0.00234451, ..., 0.        ,\n",
       "         0.01316654, 0.0139123 ],\n",
       "        [0.00144139, 0.00187336, 0.00188705, ..., 0.01316654,\n",
       "         0.        , 0.02114058],\n",
       "        [0.0025025 , 0.00262834, 0.00271677, ..., 0.0139123 ,\n",
       "         0.02114058, 0.        ]],\n",
       "\n",
       "       [[0.        , 0.01480722, 0.01089542, ..., 0.00226304,\n",
       "         0.0015254 , 0.00258565],\n",
       "        [0.01480722, 0.        , 0.01332231, ..., 0.00233848,\n",
       "         0.0018552 , 0.00270851],\n",
       "        [0.01089542, 0.01332231, 0.        , ..., 0.00244735,\n",
       "         0.00184487, 0.0028059 ],\n",
       "        ...,\n",
       "        [0.00226304, 0.00233848, 0.00244735, ..., 0.        ,\n",
       "         0.01141817, 0.01378397],\n",
       "        [0.0015254 , 0.0018552 , 0.00184487, ..., 0.01141817,\n",
       "         0.        , 0.01763642],\n",
       "        [0.00258565, 0.00270851, 0.0028059 , ..., 0.01378397,\n",
       "         0.01763642, 0.        ]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wt_etensor=np.load('/home/student5/Desktop/Energetics/elec_1.npz')\n",
    "# for x in wt_etensor:\n",
    "#     print(x)\n",
    "\n",
    "path = \"/home/student5/Desktop/Energetics/zfshomes/sstetson/End_Fall23-Pres/Analysis/FL/ff14SB/Energetics/\"\n",
    "etensor = [\n",
    "    LoadData(path + f\"Rep1/WT_PK11000/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 1001)\n",
    "] + [\n",
    "    LoadData(path + f\"Rep2/WT_PK11000/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 1001)\n",
    "] + [\n",
    "    LoadData(path + f\"Rep3/WT_PK11000/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 1001)\n",
    "] + [\n",
    "    LoadData(path + f\"Rep4/WT_PK11000/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 1001)\n",
    "] + [\n",
    "    LoadData(path + f\"Short/Rep1/WT_PK11000/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 201)\n",
    "] + [\n",
    "    LoadData(path + f\"Short/Rep2/WT_PK11000/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 201)\n",
    "] + [\n",
    "    LoadData(path + f\"Short/Rep3/WT_PK11000/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 201)\n",
    "] + [\n",
    "    LoadData(path + f\"Short/Rep4/WT_PK11000/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 201)\n",
    "] + [\n",
    "    LoadData(path + f\"Short/Rep5/WT_PK11000/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 201)\n",
    "] + [\n",
    "    LoadData(path + f\"Short/Rep6/WT_PK11000/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 201)\n",
    "] + [\n",
    "    LoadData(path + f\"Short/Rep7/WT_PK11000/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 201)\n",
    "] + [\n",
    "    LoadData(path + f\"Short/Rep8/WT_PK11000/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 201)\n",
    "] + [\n",
    "    LoadData(path + f\"Short/Rep9/WT_PK11000/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 201)\n",
    "] + [\n",
    "    LoadData(path + f\"Short/Rep10/WT_PK11000/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 201)\n",
    "]\n",
    "\n",
    "etensor = np.array(etensor)\n",
    "etensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbde52dc",
   "metadata": {
    "id": "cbde52dc"
   },
   "source": [
    "### Determining Time and Thresh Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99703da6",
   "metadata": {
    "id": "99703da6"
   },
   "outputs": [],
   "source": [
    "time = 5\n",
    "thresh = 0.002\n",
    "num_of_pcs = 5\n",
    "\n",
    "kernel = kernel_from_energy_tensor_thresh(etensor,thresh,time)\n",
    "eigens, pcs = make_shared_pca_df(kernel,num_of_pcs,show_var=True)\n",
    "\n",
    "eigens_df = pd.DataFrame(eigens)\n",
    "mean_n_eigens = eigens_df.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-arrow",
   "metadata": {
    "id": "funded-arrow"
   },
   "source": [
    "## PCA Embedding Heat Kernels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "potential-prototype",
   "metadata": {
    "id": "potential-prototype"
   },
   "outputs": [],
   "source": [
    "#getting the principle components from the heatkernel\n",
    "#changed the last argument to 2 and it changed stuff. Ask Dylan how many \"components\" I should be doing (2 or 3)? We want 3 typically\n",
    "(_,pcs) = make_shared_pca_df(kernel,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-delight",
   "metadata": {
    "id": "focused-delight"
   },
   "source": [
    "## System Heat Kernel Shared PCA Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac8c9612",
   "metadata": {},
   "outputs": [],
   "source": [
    "heat = heat_res_frame_map(kernel, pcs, 6000, 393)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da1c8457",
   "metadata": {},
   "outputs": [],
   "source": [
    "heat.to_csv(\"/home/student5/Desktop/Energetics/Processed/FL_WT_PK11000_Long+Short_Elec_1-393.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "935a0d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wt_etensor=np.load('/home/student5/Desktop/Energetics/elec_1.npz')\n",
    "# for x in wt_etensor:\n",
    "#     print(x)\n",
    "\n",
    "path = \"/home/student5/Desktop/Energetics/zfshomes/sstetson/End_Fall23-Pres/Analysis/FL/ff14SB/Energetics/\"\n",
    "etensor = [\n",
    "    LoadData(path + f\"Rep1/Y220C/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 1001)\n",
    "] + [\n",
    "    LoadData(path + f\"Rep2/Y220C/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 1001)\n",
    "] + [\n",
    "    LoadData(path + f\"Rep3/Y220C/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 1001)\n",
    "] + [\n",
    "    LoadData(path + f\"Rep4/Y220C/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 1001)\n",
    "] + [\n",
    "    LoadData(path + f\"Short/Rep1/Y220C/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 201)\n",
    "] + [\n",
    "    LoadData(path + f\"Short/Rep2/Y220C/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 201)\n",
    "] + [\n",
    "    LoadData(path + f\"Short/Rep3/Y220C/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 201)\n",
    "] + [\n",
    "    LoadData(path + f\"Short/Rep4/Y220C/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 201)\n",
    "] + [\n",
    "    LoadData(path + f\"Short/Rep5/Y220C/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 201)\n",
    "] + [\n",
    "    LoadData(path + f\"Short/Rep6/Y220C/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 201)\n",
    "] + [\n",
    "    LoadData(path + f\"Short/Rep7/Y220C/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 201)\n",
    "] + [\n",
    "    LoadData(path + f\"Short/Rep8/Y220C/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 201)\n",
    "] + [\n",
    "    LoadData(path + f\"Short/Rep9/Y220C/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 201)\n",
    "] + [\n",
    "    LoadData(path + f\"Short/Rep10/Y220C/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 201)\n",
    "]\n",
    "\n",
    "etensor = np.array(etensor)\n",
    "etensor\n",
    "\n",
    "### Determining Time and Thresh Parameters\n",
    "\n",
    "time = 5\n",
    "thresh = 0.002\n",
    "num_of_pcs = 5\n",
    "\n",
    "kernel = kernel_from_energy_tensor_thresh(etensor,thresh,time)\n",
    "eigens, pcs = make_shared_pca_df(kernel,num_of_pcs,show_var=True)\n",
    "\n",
    "eigens_df = pd.DataFrame(eigens)\n",
    "mean_n_eigens = eigens_df.mean(axis=0)\n",
    "\n",
    "## PCA Embedding Heat Kernels:\n",
    "\n",
    "#getting the principle components from the heatkernel\n",
    "#changed the last argument to 2 and it changed stuff. Ask Dylan how many \"components\" I should be doing (2 or 3)? We want 3 typically\n",
    "(_,pcs) = make_shared_pca_df(kernel,3)\n",
    "\n",
    "## System Heat Kernel Shared PCA Plots\n",
    "\n",
    "heat = heat_res_frame_map(kernel, pcs, 6000, 393)\n",
    "\n",
    "heat.to_csv(\"/home/student5/Desktop/Energetics/Processed/FL_Y220C_Long+Short_Elec_1-393.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad8e080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wt_etensor=np.load('/home/student5/Desktop/Energetics/elec_1.npz')\n",
    "# for x in wt_etensor:\n",
    "#     print(x)\n",
    "\n",
    "path = \"/home/student5/Desktop/Energetics/zfshomes/sstetson/End_Fall23-Pres/Analysis/FL/ff14SB/Energetics/\"\n",
    "etensor = [\n",
    "    LoadData(path + f\"Rep1/Y220C_PK11000/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 1001)\n",
    "] + [\n",
    "    LoadData(path + f\"Rep2/Y220C_PK11000/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 1001)\n",
    "] + [\n",
    "    LoadData(path + f\"Rep3/Y220C_PK11000/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 1001)\n",
    "] + [\n",
    "    LoadData(path + f\"Rep4/Y220C_PK11000/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 1001)\n",
    "] + [\n",
    "    LoadData(path + f\"Short/Rep1/Y220C_PK11000/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 201)\n",
    "] + [\n",
    "    LoadData(path + f\"Short/Rep2/Y220C_PK11000/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 201)\n",
    "] + [\n",
    "    LoadData(path + f\"Short/Rep3/Y220C_PK11000/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 201)\n",
    "] + [\n",
    "    LoadData(path + f\"Short/Rep4/Y220C_PK11000/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 201)\n",
    "] + [\n",
    "    LoadData(path + f\"Short/Rep5/Y220C_PK11000/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 201)\n",
    "] + [\n",
    "    LoadData(path + f\"Short/Rep6/Y220C_PK11000/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 201)\n",
    "] + [\n",
    "    LoadData(path + f\"Short/Rep7/Y220C_PK11000/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 201)\n",
    "] + [\n",
    "    LoadData(path + f\"Short/Rep8/Y220C_PK11000/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 201)\n",
    "] + [\n",
    "    LoadData(path + f\"Short/Rep9/Y220C_PK11000/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 201)\n",
    "] + [\n",
    "    LoadData(path + f\"Short/Rep10/Y220C_PK11000/normal/elec_1-393/elec_{x}.npz\") for x in range(1, 201)\n",
    "]\n",
    "\n",
    "etensor = np.array(etensor)\n",
    "etensor\n",
    "\n",
    "### Determining Time and Thresh Parameters\n",
    "\n",
    "time = 5\n",
    "thresh = 0.002\n",
    "num_of_pcs = 5\n",
    "\n",
    "kernel = kernel_from_energy_tensor_thresh(etensor,thresh,time)\n",
    "eigens, pcs = make_shared_pca_df(kernel,num_of_pcs,show_var=True)\n",
    "\n",
    "eigens_df = pd.DataFrame(eigens)\n",
    "mean_n_eigens = eigens_df.mean(axis=0)\n",
    "\n",
    "## PCA Embedding Heat Kernels:\n",
    "\n",
    "#getting the principle components from the heatkernel\n",
    "#changed the last argument to 2 and it changed stuff. Ask Dylan how many \"components\" I should be doing (2 or 3)? We want 3 typically\n",
    "(_,pcs) = make_shared_pca_df(kernel,3)\n",
    "\n",
    "## System Heat Kernel Shared PCA Plots\n",
    "\n",
    "heat = heat_res_frame_map(kernel, pcs, 6000, 393)\n",
    "\n",
    "heat.to_csv(\"/home/student5/Desktop/Energetics/Processed/FL_Y220C_PK11000_Long+Short_Elec_1-393.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "AmberTools23",
   "language": "python",
   "name": "ambertools23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
